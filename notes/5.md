## 

**指令重排问题**

```c++
int a = 0；
bool flag=false；
void thread1()
{
	a = 1；
	flag=true；
}

void thread2()
{
	if (flag == true){
		assert(a == 1);
	}
}

```

我们期待的执行顺序：

![在这里插入图片描述](static\5\ef36ef6989444ec2840b0508be59c143.png)

实际可能产生的内存顺序，这种重排有可能会导致一个线程内相互之间不存在依赖关系的指令交换执行顺序，以获得更高的执行效率。

![在这里插入图片描述](static\5\2e6fc7c5cbc840409677911e0632e876.png)

解决办法：
一个比较稳妥的办法就是对于共享变量的访问进行加锁，加锁可以保证对临界区的互斥访问、如果觉得加锁操作过重太麻烦而不想加锁呢？C++11提供了一些原子变量与原子操作来支持。

# 5.2

## 5.2.1

### 内存序是什么

内存序（Memory Order）是并发编程中的一个概念，特别是在涉及到多线程访问共享数据时。它定义了操作在多个处理器上的可见性和执行顺序，是理解和使用原子操作（Atomic Operations）时必须考虑的重要因素。在C++11及以后的版本中，内存序是通过一系列预定义的内存序常量来指定的，这些常量决定了编译器和处理器对内存访问和修改操作的重排序（Reordering）程度。

不同的内存序选项提供了不同级别的保证：

1. **memory_order_relaxed**: 最宽松的内存序，不对执行顺序做任何保证，只保证原子操作的原子性。它允许编译器和处理器对操作进行重排序，只要原子性得以保持。

2. **memory_order_consume**: 适用于读取操作。它保证基于特定加载操作的结果的操作不会被重排序到加载操作之前（在现代编译器中，通常与memory_order_acquire有相同的效果，因为很难有效实现）。

3. **memory_order_acquire**: 用于读取操作，表示在当前读取操作之后的所有读取和写入操作必须在此读取操作之后执行。它确保当前线程读取的值是最新的，防止了读取操作被重排序到它之前的写入操作之前。

4. **memory_order_release**: 用于写入操作，表示在当前写入操作之前的所有读取和写入操作必须在此写入操作之前执行。它确保当前线程对共享变量的修改对其他线程是可见的，防止了写入操作被重排序到它之后的读取操作之前。

   ```c++
   std::atomic<bool> x, y;
   std::atomic<int> z;
    
   void write_x_then_y() {
     // 保证读入y之前，一定读入了x，read_y_then_x()函数里面的z不会是0
     x.store(true, std::memory_order_relaxed);
     y.store(true, std::memory_order_release);
   }
    
   void read_y_then_x() {
     while (!y.load(std::memory_order_acquire));
     if (x.load(std::memory_order_relaxed)) {
       ++z;
     } 
   }
   ```

5. **memory_order_acq_rel**: 用于读-改-写操作，结合了memory_order_acquire和memory_order_release的保证。它确保了之前的操作不会被重排序到当前操作之后，同时之后的操作也不会被重排序到当前操作之前。

6. **memory_order_seq_cst**: 最严格的内存序，提供顺序一致性（Sequential Consistency）。它保证了所有线程看到的操作顺序是一致的，并且执行顺序符合程序的原始顺序。这是默认的内存序，也是最容易理解和使用的，但可能会因为额外的同步开销而影响性能。

内存序的选择取决于你的具体需求。如果你需要最大的性能并且能够接受较复杂的同步逻辑，你可能会选择更宽松的内存序。如果你需要简单、直观的同步保证，顺序一致性（memory_order_seq_cst）可能是更好的选择。正确使用内存序对于避免数据竞争和保证多线程程序的正确性至关重要。

### 为什么有内存序

原子类型提供了不同的内存序选项，如`memory_order_relaxed`, `memory_order_release`, `memory_order_seq_cst`等，是为了给程序员提供更多的控制权，以便根据特定的同步需求和性能目标来选择最合适的内存顺序模型。这些内存序选项允许程序员在保证必要的同步保障的同时，减少不必要的同步开销。 下面是为什么会存在这些内存序选项的原因：

1. **性能优化**：默认的内存序`memory_order_seq_cst`提供了最强的同步保障，但也可能导致性能开销。在某些情况下，程序不需要这么强的保障，使用更宽松的内存序可以减少同步开销，提高程序性能。
2. **灵活性**：不同的内存序提供了不同级别的同步保障。例如，`memory_order_release`用于写操作，确保写入的数据对后续获取同一数据的线程可见；`memory_order_acquire`用于读操作，确保读操作之后的代码能看到之前的写入。`memory_order_relaxed`则提供了最少的同步保障，仅保证了操作的原子性。
3. **硬件特性**：不同的处理器架构有不同的内存模型，一些处理器可能对内存操作的重排序有更多的限制。内存序选项允许程序在不同的硬件上实现最优的同步策略。
4. **特定同步需求**：在某些并发模式中，可能只需要保证一部分操作的顺序性。例如，只有在某些特定的同步点需要强顺序性，而在其他时候可以允许更多的自由度。内存序选项使得这种精细控制成为可能。
5. **编译器优化**：提供不同的内存序选项允许编译器在不违反程序员指定的同步需求的前提下，进行更多的优化。例如，`memory_order_relaxed`允许编译器和处理器进行更多的指令重排序。
6. **并发模式的构建块**：不同的内存序选项可以被用来构建复杂的并发模式和数据结构，如无锁队列、计数器和其他并发控制结构。

总结来说，原子类型的不同内存序选项提供了在保障数据一致性和同步需求的同时，对性能进行细粒度控制的能力。这些选项的存在使得并发编程更加灵活，允许开发者根据具体的应用场景和性能要求来选择最合适的同步策略。

# 5.3

## 5.3.5 

### atomic_thread_fence

与上面的有些许不同，在于前后。

`std::atomic_thread_fence` 是 C++ 标准库中提供的一个函数，用于在多线程编程中控制内存访问的顺序和一致性。它允许程序员在特定位置显式地指定内存屏障，以**确保在屏障前后的内存操作按照指定的顺序进行**。

这个函数可以在两种模式下使用：`std::memory_order_acquire` 和 `std::memory_order_release`，分别用于读取和写入内存时的顺序控制。

- `std::memory_order_acquire`: 该模式下的内存屏障确保在**该屏障之后的所有读写操作都在该屏障之前的读取操作之后完成**。这意味着在执行该屏障之后，所有对共享变量的读取操作都将看到在该屏障之前执行的写入操作。

- `std::memory_order_release`: 该模式下的内存屏障确保在**该屏障之前的所有读写操作都在该屏障之后的写操作之前完成**。这意味着在执行该屏障之前，所有对共享变量的写入操作都将在该屏障之后被其他线程看到。

这两种内存屏障可以用于确保原子操作的顺序一致性，防止指令重排和缓存一致性问题，从而提供更强的多线程编程保证。使用内存屏障时，需要注意正确选择适当的模式，并将其放置在适当的位置，以确保程序的正确性和性能。